## Overview

In this section, we will be provisioning/configuring the following:
1. Creating Launch Configuration
2. Deploy app1 with Auto Scaling Group 
3. Provisioning Load Balancer
4. Configuring Public DNS
5. Configuring SSL/TLS for Load Balancer
6. Auto Scaling Group Scaling in and out

## 1. Creating Launch Configuration

Open the **Auto Scaling** Product page and select the **Launch Configuration** Tab

![](figures/04-app1.png)

Click on the **Create** button to create a new Group Launch Configuration

![](figures/04-app1-1.png)

Create the Launch configuration as per the following specification:

| Param              | Value                                                                                         |
| ------------------ | --------------------------------------------------------------------------------------------- |
| Billing Model      | Pay-as-you-go                                                                                 |
| Availability Zones | Select all Availability Zones                                                                 |
| Machine Type       | Standard SA2 (Any 1 or 2 CPU with 1 or 2GB of MEM)                                            |
| Image              | CentOS 7.9 64bit                                                                              |
| Public IP          | Necessary (For this Demo as you need a Public IP to download the resources in the COS Bucket) |

Select the server model as shown below, feel free to change pick a different Instance Type for the purpose of this lab.

![](figures/04-app1-2.png)
![](figures/04-app1-3.png)

Complete your configuration by adding the relevant details
For the **Custom data** field, we will fill in the following values:

```bash
#!/bin/bash
mkdir -p /usr/local/etc/app1 /usr/local/bin/app1

wget "https://ea54c6-lab-1323449807.cos.ap-singapore.myqcloud.com/app1/app1" -O /usr/local/bin/app1/app1
chmod +x /usr/local/bin/app1/app1

wget "https://ea54c6-lab-1323449807.cos.ap-singapore.myqcloud.com/app1/config.yaml" -O /usr/local/etc/app1/config.yaml

cat > /etc/systemd/system/app1.service <<EOF
[Unit]
Description=Go Application Service

[Service]
ExecStart=/bin/bash -c '/usr/local/bin/app1/app1 -c /usr/local/etc/app1/config.yaml >> /tmp/app1.log 2>&1'
WorkingDirectory=/usr/local/bin/
User=root
Restart=always
Type=simple
KillMode=mixed

[Install]
WantedBy=multi-user.target
EOF

systemctl enable app1
systemctl daemon-reload
echo "app1 enabled, now starting..."
systemctl start app1
```


![](figures/04-app1-4.png)
![](figures/04-app1-5.png)

![](figures/04-app1-6.png)

We're now able to see the **Launch configuration** we've created

![](figures/04-app1-7.png)


## 2. Deploy app1 with Auto Scaling Group

Now that we've created a **Launch Configuration**, we'll create an **Auto Scaling Group**. Navigate over to the **Scaling Group** Tab on the side bar and click on **Create**

![](figures/04-app1-8.png)

| Param                      | Value                                                                                                     |
| -------------------------- | --------------------------------------------------------------------------------------------------------- |
| Project                    | Take note that the CVM created by the Scaling Group will inherit the project that the Scaling Group is in |
| Min capacity               | 1                                                                                                         |
| Initial capacity           | 1                                                                                                         |
| Max capacity               | 3                                                                                                         |
| Launch Configuration       | Previously created Launch configuration                                                                   |
| Supported network          | Previously created VPC                                                                                    |
| Load balancing             | Previously created Load Balancer                                                                          |
| Instance port              | 80                                                                                                        |
| Instance creation strategy | Multiple availability zones (subnets) distribution                                                        |

![](figures/04-app1-9.png)

Skip the Load Balancer configuration by clicking **Next step: Instance Allocation**

![](figures/04-app1-10.png)

![](figures/04-app1-11.png)

For the Instance creation policy, select the **Multiple availability zones (subnets) distribution** option.

![](figures/04-app1-12.png)

Click into the scaling group we've just created to view its details

![](figures/04-app1-13.png)

We can navigate to the **Associated Instances** Tab to see the instances that our Auto Scaling Group has created.

![](figures/04-app1-14.png)

We can now test if we're able to access `app1` using a Web Browser.
Enter the following link into your browser `http://<instance-ip>:8888`

![](figures/04-app1-15.png)

## 3. Provisioning Load Balancer

Previously, we saw that we could access the CVM Instance created by the Auto Scaling Group by its IP. However, as we have more instances in the Auto Scaling Group, we will see that each instance has a different IP, making it difficult to manage using purely IPs.

As seen previously during the creation of the Auto Scaling Group, there is an option to attach a Load Balancer, giving us the ability to Load Balance over multiple instances.

Click on the **create one** Text Button to create a Load Balancer

![](figures/04-app1-16.png)

Click on the **Create** Button

![](figures/04-app1-17.png)

Configure the Load Balancer with the following settings and click **Buy now** on the bottom right

![](figures/04-app1-18.png)

Head to the Cloud Load Balancer page, we should see the Load Balancer we've just created.

When we first create a Load Balancer, the Load Balancer will not be Listening or Forwarding any traffic when it has been just created. 

To configure its Listener, click on the **Configure Listener** Button

![](figures/04-app1-19.png)

Click on **Create** in the **HTTP/HTTPS Listeners** section

![](figures/04-app1-20.png)

Configure the Name and the Listened protocol:port

The Listened protocol:port refers to the protocol and port number you want the Load Balancer to be listening on for request

![](figures/04-app1-21.png)

Now we've created a Listener, the Load Balancer will be able to receive traffic at the configure Protocol and Port.

We will now create a Forwarding rule to direct the traffic the Load Balancer Listened for to the Auto Scaling Group's CVM Instances.

Expand the Listener by clicking on the `+` Icon beside the name

![](figures/04-app1-22.png)

Click on the **Create now** to create a new Forwarding Rule.

![](figures/04-app1-23.png)

When configuring a Forwarding rule, we will need to designate the domain we're binding the Load Balancer to.

In this example, we will be using the convention `<code>-app1.<your-domain>.<tld>` for the domain we'll create later on.

![](figures/04-app1-24.png)

We can also see there are configurations for Health checks, for this lab's deployment, we'll leave the settings default

![](figures/04-app1-25.png)

Finally, we'll also leave the Session persistence settings as its default (Off) as our applications don't require Session persistence.

![](figures/04-app1-26.png)

Now that we've created the Forwarding rule, you should see a record of it under the Listener

![](figures/04-app1-27.png)

Now head back to the ASG's page and click on **Add** in the **Load balancer** section

![](figures/04-app1-28.png)

Configure the Load Balancer as show below for the ASG

![](figures/04-app1-29.png)

We should now see the configured Load Balancer as shown below

![](figures/04-app1-30.png)

## 4. Configuring Public DNS

When configuring the Load Balancer Listener, we previously had to set the domain the Load Balancer is being accessed from.

In the previous step, we didn't create the Public DNS Records on our domain provider. In this step, we will be creating the records.

As mentioned previously, the domain in this example was bought on Tencent Cloud which uses the DNSPod platform for configuring its DNS Records. Head over to the DNSPod page and click on the **Add Record**

![](figures/04-app1-31.png)

Create a CNAME Record with the Load Balancer's Domain Name.
Set the Host to the domain we set when creating the Load Balancer previously.

![](figures/04-app1-32.png)

We can now test the hostname on the Browser

![](figures/04-app1-33.png)

## 5. Configuring SSL/TLS for Load Balancer

Previously we provisioned an SSL/TLS Certificate for our Nginx Web Server. This time, we will configure the SSL/TLS on the Load Balancer instead.

Let us start but creating the SSL/TLS Certificate for the domain record we just created

Click on **Apply for free certificate**

![](figures/04-app1-34.png)

Enter the domain that we previously configured on the Load Balancer

![](figures/04-app1-35.png)

Verify the domain by creating the CNAME record

![](figures/04-app1-36.png)

Head to the DNSPod page to add the CNAME Record for verification

![](figures/04-app1-37.png)

After adding the record, head back to the certificate application page and click on **Validate domain**

![](figures/04-app1-38.png)

After the domain has been verified, we'll be able to see the SSL/TLS Certificate in the Certificate Management Page

![](figures/04-app1-39.png)

Now we'll need to create a different Listener for a HTTPS Listener. Click on the **Create** button

![](figures/04-app1-40.png)

Configure the Listener and select the **Server certificate**

![](figures/04-app1-41.png)

Create a **Forwarding rule** by clicking the **Create now** Text button

![](figures/04-app1-42.png)

Configure the Domain as previously created in the Public DNS Records

![](figures/04-app1-43.png)
![](figures/04-app1-44.png)
![](figures/04-app1-45.png)

Now we need to change the previously assigned HTTP Listener to the one we've just created. Head over to the Auto Scaling Group we previously created, and click on the **3 Dots**

![](figures/04-app1-46.png)

Change the Listener to the HTTPS one we've just created and click **Save**

![](figures/04-app1-47.png)

We can now test the service with the HTTPS link to check if the Load Balancer's HTTPS works as expected.

You should see HTTPS properly configured along with the "Healthcheck" message.

![](figures/04-app1-48.png)

## 6. Auto Scaling Group Scaling in and out

An Auto Scaling Group is able to Scale out and in automatically when certain conditions are met. In to achieve the scaling, we need to configure an Alarm Trigger Policy

![](figures/04-app1-49.png)

In the example below, we've configured it to scale out when there are more than 3 consecutive TCP connections over the span of 1 min. If the condition is met, and instance will be added

![](figures/04-app1-50.png)
![](figures/04-app1-51.png)

We do the same as well for the opposite condition, when there is less than 3 consecutive connections over the span of 1 min, scale inwards.

![](figures/04-app1-52.png)
![04-app1-53.png](figures/04-app1-53.png)

Run the following command with the Apache Benchmark Utility `ab`

```bash
# Make request to cause the autoscaling to scale out
$ ab -c 100 -t 30 -n 2000 https://<code>-app1.tam-lab.xyz
```

When the Auto Scaling Group scales out, you're able to see it in the **Query scaling activities** tab

![](figures/04-app1-54.png)

Furthermore, you're also able to see an additional VM added in the **Associated instances**

![04-app1-55.png](figures/04-app1-55.png)

Stop the command by pressing `Ctrl-C` in the terminal and head back to the page. 

After some time, you will see that the extra added instances are removed as the Auto Scaling Group Scales inwards.

![](figures/04-app1.png)
